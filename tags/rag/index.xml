<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>RAG on 元视角</title><link>https://blog.yuanpei.me/tags/rag/</link><description>Recent content in RAG on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 24 Aug 2025 20:42:23 +0000</lastBuildDate><atom:link href="https://blog.yuanpei.me/tags/rag/index.xml" rel="self" type="application/rss+xml"/><item><title>基于 Supabase 的 AI 应用开发探索</title><link>https://blog.yuanpei.me/posts/supabase-powered-ai-app-exploration/</link><pubDate>Sun, 24 Aug 2025 20:42:23 +0000</pubDate><guid>https://blog.yuanpei.me/posts/supabase-powered-ai-app-exploration/</guid><description>引言 最近看到一个有趣的观点：当你试图对 AI 进行某种界定时，会发现诸如知识密集型、资本密集型、劳动密集型、资源密集型这些类别，似乎都适用于它。首先，AI 无疑是知识密集型和资本密集型的。然而，考虑到数据标注等工作需要投入大量人力，AI 表现出劳动密集型的特征。与此同时，AI 的训练和推理依赖庞大的算力，而这背后离不开巨大的资源支持，所以它还具备资源密集型的属性。这种“什么都是，又什么都不是”、难以简单归类的状态，恰恰构成了 AI 产业最根本的特性。在持续使用 Claude Code 两个月以后，一切都归于寂静，曾经的 Cursor 和 Windsurf 亦是如此。秋风渐起，天气转凉，最近发布的 GPT-5 和 DeepSeek-v3.1 表现不温不火，反倒是谷歌凭借 Nano Banana 再次成为焦点。当然，相比于讨论这些无关紧要的事情，我更关注 AI 技术在实际场景中的落地。因此，在这篇博客中，我想和大家分享如何基于 Supabase 快速构建一个可用的 AI 应用。
为什么选择 Supabase? 时间来到 2025 年，横亘在我们面前的最大危机，已从「怎么做」变成「做什么」。Know-How 里的 Know 与 How，正在逐渐被 AI 接管，留给我们的只剩下 What——我们究竟该让技术指向何方。放眼望去，市面上可供开发 AI 应用的工具琳琅满目，令人目不暇接。以笔者为例，Cursor、Windsurf、Cline、Claude Code、Gemini CLI，各种工具几乎都尝试了一遍，而如今最常用的，反而是 VSCode 内置的 GitHub Copilot。结合我有限的认知，我对这些工具做了如下划分，大家可以按图索骥，选择适合自己的工具进行尝试：
编辑器/IDE/插件类：Cursor、Windsurf、Cline、GitHub Copilot 等 CLI/工具类： Claude Code、Gemini CLI 等 一站式部署类：Bolt.New、v0 等 低代码/工作流：Coze、Dify、n8n 等 代码框架：LangGraph、Semantic Kernel、AutoGen、CrewAI 等 那么，相对于这些这些方案，Supabase 有什么优势呢？开发 AI 应用时，我们真正需要的，是一个既能满足 AI 应用需求，又能快速开发和部署的平台。而 Supabase 正是这样一个理想的平台，它具有以下优势：</description></item><item><title>RAG 的是与非、Rewrite 和 Rerank</title><link>https://blog.yuanpei.me/posts/the-true-or-false-rewrite-rerank-of-rag/</link><pubDate>Fri, 26 Apr 2024 09:29:47 +0000</pubDate><guid>https://blog.yuanpei.me/posts/the-true-or-false-rewrite-rerank-of-rag/</guid><description>有时候，我觉得人类还真是种擅长画地为牢的动物，因为突然发现，当人们以文化/理念的名义形成团体/圈子的时候，其结局都不可避免地走向了筛选和区分的道路。或许，大家都不约而同地笃信，在成年人的世界里，那条不成文的社交潜规则——“只筛选不教育，只选择不改变”。与千百年前百家争鸣不同，团体/圈子间并不热衷于交流，倒像是一种标签化的分类方式，甚至是一种非黑即白的二元分类方式。比如，通常人们认为男性不能讨论女性主义，可我经常在女性主义视角下看到对男性的讨论。女性朋友们一致认为，女性种种不幸完全是由男性以及男性背后的父权造成的。于是，在小红书上打着不被定义的标签的女性们，自顾自地定义着别人。亦或者，在这个内卷的世界里，人们被互相定义、被资本定义、被用户画像定义、被美颜相机定义……这种种的定义，最终会成为我们所有人的宿命。鲁迅先生说，中国人的性情是喜欢调和折中的，对此我表示怀疑。因为，以如今的现状而言，中国人或许更喜欢玉石俱焚。在我看来，标签是定义、是附和、是选择，无论我们是否知晓，那条路是否能代表未来。
是非善恶 最近，Meta 发布了 Llama3，一时风光无二。微软不甘示弱，紧随其后发布了 Phi-3。曾经，我认为在小红书上检索信息比百度更高效，可当我批评完百度的竞价排名后，我发现小红书上的广告问题更严重，特别是 AI 的加入让这一问题愈发严重。回到 AI 话题，最近人们对于大模型的态度大致可以总结为：对 Llama3 和 Phi-3 寄予厚望，认为它们接近 GPT-4 的水平，而对 OpenAI 以及 GPT-5 的前景则持续看衰。我不太关心这些预期，我在意的是新模型发布以后，各路牛鬼蛇神都可以活跃起来。小红书上有一篇帖子提到，Llama3 的发布使得本地化 RAG 更有意义，并分享了一个使用 LlamaIndex 实现 RAG 的案例，随后是小红书上经典的套路：私信、拉群、发链接。我对帖子中的观点保留态度，因为 Llama3 作为大型模型，主要解决的是推理问题；而 RAG 是检索 + 生成的方案，其核心在于提高检索的召回率，即：问题与文本块之间的相关性。显然，无论 Llama3 是否发布，RAG 都能正常落地。大型模型的推理能力，影响的是最终的生成结果，而非检索的召回率。
最简单的 RAG 范式 故事的结局是我遭到了反驳，对方质疑我对 RAG 的理解，并建议我阅读她主页的某个帖子，据说是 RAG 论文作者在斯坦福的讲课内容。我原本是打算去学习的，可戏剧性的是，我被对方拉黑了。我还能再说什么呢？当然选择原谅对方。为了证明我对 RAG 的理解没有偏差，我决定分享我最近对于 Rewrite 和 Rerank 的体悟。我想明确指出的是，无需使用 Llama3，只要提升检索部分的召回率，RAG 方案完全可以实施。实际上，我们甚至都不需要 GPT-4 级别的模型，选择一个合适的小模型足矣。我意识到，我最大的错误在于，试图在一个以信息差为生意的人面前打破信息壁垒，帮助他人摆脱知识的诅咒。正如我之前所述，某些团体或圈子的目的并非促进信息流通和交流，而是为了向特定的人群提供通行证，以便在来来往往的人群中筛选和区分同类。或许，你会认为你已经筛选出你想要的人，但从更广阔的视角来看，这不过是另一种傲慢与偏见。当然，你们权利忽视这些问题，就像我不在乎周围环境如何一样。作为一个崇尚科学的人，我只关心真理，除非你的真理更为真实。
实现 Rewrite 在 RAG 的语境中，Rewrite 是重写或者改写的意思。此时，诸位或许会困惑，为什么需要对用户输入的问题进行二次加工呢？在程序员群体中，有一本非常经典的书 ——《提问的智慧》，其核心观点是：在技术的世界里，当你提出一个问题时，最终能否得到有用的答案，往往取决于你提问和追问的方式。以此作为类比，众所周知，人类的输入通常随性而模糊，特别是在使用自然语言作为交互媒介的时候。在这种情况下，大语言模型难以准确理解人类的真实意图。因此，就需要对用户的原始查询进行改写，通过生成多个语义相似但是表述不同的问题，来提高或增强检索的多样性和覆盖面。由于重写后的查询会变得更为具体，故而，Rewrite 在缩小检索范围、提高检索相关性方面有一定的优势。例如，下面的提示词实现了对用户输入的改写：
通过提示词实现 Rewrite 实际效果如何呢？我们可以分别在 Kimi 和 ChatGPT 中进行测试。如下图所示，左边为 Kimi，右边为 ChatGPT：</description></item><item><title>基于 LLaMA 和 LangChain 实践本地 AI 知识库</title><link>https://blog.yuanpei.me/posts/practice-local-ai-knowledg-base-based-on-llama-and-langchain/</link><pubDate>Thu, 29 Feb 2024 10:30:47 +0000</pubDate><guid>https://blog.yuanpei.me/posts/practice-local-ai-knowledg-base-based-on-llama-and-langchain/</guid><description>有时候，我难免不由地感慨，真实的人类世界，本就是一个巨大的娱乐圈，即使是在英雄辈出的 IT 行业。数日前，Google 正式对外发布了 Gemini 1.5 Pro，一个建立在 Transformer 和 MoE 架构上的多模态模型。可惜，这个被 Google 寄予厚望的产品并未激起多少水花，因为就在同一天 OpenAI 发布了 Sora，一个支持从文字生成视频的模型，可谓是一时风光无二。有人说，OpenAI 站在 Google 的肩膀上，用 Google 的技术疯狂刷屏。此中曲直，远非我等外人所能预也。我们唯一能确定的事情是，通用人工智能，即：AGI（Artificial General Intelligence）的实现，正在以肉眼可见的速度被缩短，以前在科幻电影中看到的种种场景，或许会比我们想象中来得更快一些。不过，等待 AGI 来临前的黑夜注定是漫长而孤寂的。在此期间，我们继续来探索 AI 应用落地的最佳实践，即：在成功部署本地 AI 大模型后，如何通过外挂知识库的方式为其 “注入” 新的知识。
从 RAG &amp;amp; GPTs 开始 在上一期博客中，博主曾经有一个困惑，那就是当前阶段 AI 应用的最佳实践到底是什么？站在 2023 年的时间节点上，博主曾经以为未来属于提示词工程(Prompt Engineering)，而站在 2024 年的时间节点上，博主认为 RAG &amp;amp; GPTs 在实践方面或许要略胜一筹。在过去的一年里，我们陆陆续续看到像 Prompt Heroes、PromptBase、AI Short&amp;hellip;等等这样的提示词网站出现，甚至提示词可以像商品一样进行交易。与此同时，随着 OpenAI GPT Store 的发布，我们仿佛可以看到一种 AI 应用商店的雏形。什么是 GPTs 呢？通常是指可以让使用者量身定做 AI 助理的工具。譬如，它允许用户上传资料来丰富 ChatGPT 的知识库，允许用户使用个性化的提示词来指导 ChatGPT 的行为，允许用户整合各项技能(搜索引擎、Web API、Function Calling)&amp;hellip;等等。我们在上一期博客中提到人工智能的 “安卓时刻”，一个重要的契机是目前产生了类似应用商店的 GPT Store，如下图所示：</description></item></channel></rss>